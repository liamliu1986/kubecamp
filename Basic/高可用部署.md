# 高可用部署

## 准备

关闭selinux，修改配置文件

```bash
setenforce 0
sed -i s/SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/config
```

关闭防火墙

```bash
systemctl stop firewalld
systemctl disable firewalld
```

关闭swap

```bash
echo "swapoff -a" >> /etc/profile
source /etc/profile
sed -i /swap/d /etc/fstab
```

添加内核模块

```bash
cat > /etc/sysconfig/modules/ipvs.modules << EOF
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- br_netfilter
modprobe -- overlay
EOF
source /etc/sysconfig/modules/ipvs.modules
```



修改内核参数

```bash
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
sysctl --system
```

## 安装docker

清理系统原有版本

```bash
    yum remove docker \
            docker-client \
            docker-client-latest \
            docker-common \
            docker-latest \
            docker-latest-logrotate \
            docker-logrotate \
            docker-engine
```

安装yum管理工具

```bash
dnf install -y yum-utils    
```

添加yum仓库

```bash
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
```

安装docker引擎

```bash
dnf install docker-ce docker-ce-cli containerd.io -y
```

启动docker

```bash
systemctl start docker
```

自启动docker

```bash
systemctl enable docker
```

docker加速配置

```bash
sudo tee /etc/docker/daemon.json <<EOF
{
  "registry-mirrors": ["https://tlwy9ltd.mirror.aliyuncs.com"],
  "bip": "1.10.0.1/24",
  "exec-opts": ["native.cgroupdriver=systemd"]
}
EOF
systemctl daemon-reload
systemctl restart docker

containerd config default | sudo tee /etc/containerd/config.toml
# 添加如下内容
sandbox_image = "registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6"
  SystemdCgroup = true


      [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
          endpoint = ["https://tlwy9ltd.mirror.aliyuncs.com"]

      

systemctl restart containerd
systemctl enable containerd

tee /etc/crictl.yaml <<EOF
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
EOF
```

添加阿里云源

```bash
cat > /etc/yum.repos.d/kubernetes.repo <<EOF 
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```

安装kubeadm，kubelet，kubectl，worker节点只安装kubelet就可以

```bash
dnf install kubeadm kubelet kubectl -y

systemctl enable kubelet
```

配置时间同步

```bash
dnf install -y chrony
sed -i s#pool\ \.*\ iburst#pool\ ntp.aliyun.com\ iburst#g /etc/chrony.conf
systemctl restart chronyd

chronyc sources
timedatectl set-timezone Asia/Shanghai
```

修改hosts文件

```bash
echo "$(ip a|grep inet|grep 172.|awk '{print $2}'|awk -F/ '{print $1}') $(hostname)">> /etc/hosts
```

配置IPVS

```bash
dnf install ipset ipvsadm tc -y
```

安装keepalived

```bash
dnf install -y keepalived
```

配置keepalived主

```bash
cat > /etc/keepalived/keepalived.conf <<EOF 
! Configuration File for keepalived
 
global_defs {
   router_id k8s
   script_user root  //执行的用户
   enable_script_security
}
 
vrrp_script check_apiserver {
    script "curl -k https://127.0.0.1:6443/healthz"
    interval 3
    weight -2
    fall 10
    rise 2
}
 
vrrp_instance VI_1 {
    state MASTER 
    interface ens18 //网络ID ifcfg-ens33
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass neuedu.com
    }
    virtual_ipaddress {
        172.18.5.20/23
    }
    track_script {
        check_haproxy
    }
}
EOF
```

配置keepalived备

```bash
cat > /etc/keepalived/keepalived.conf <<EOF 
! Configuration File for keepalived
 
global_defs {
   router_id k8s
   script_user root  //执行的用户
   enable_script_security
}
 
vrrp_script check_apiserver {
    script "curl -k https://127.0.0.1:6443/healthz"
    interval 3
    weight -2
    fall 10
    rise 2
}
 
vrrp_instance VI_1 {
    state BACKUP 
    interface ens18 //网络ID ifcfg-ens33
    virtual_router_id 51
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass neuedu.com
    }
    virtual_ipaddress {
        172.18.5.20/23
    }
    track_script {
        check_haproxy
    }
}
EOF
```

重启keepalived

```bash
systemctl restart keepalived
systemctl enable keepalived
```

命令补全

```bash
dnf install -y bash-com*
source /etc/profile
```

编写kube-admin.yaml

```yaml
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: 1.24.0
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
clusterName: kubeneuedu-pro
controlPlaneEndpoint: "172.18.5.20:6443"
networking:
    podSubnet: 1.233.0.0/16
    serviceSubnet: 1.234.0.0/16
dns:
    type: CoreDNS
    imageRepository: coredns
    imageTag: 1.8.0

---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs
```

初始化集群：


```bash
kubeadm config images pull --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers
kubeadm init --config kube-admin.yaml --upload-certs
```

获取集群信息：

```bash
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join 172.18.5.20:6443 --token 48f2sx.qsfodgd8wyanmycj \
        --discovery-token-ca-cert-hash sha256:4458c26834f6912027b169bc63fbdbe61bfb9c8b88f5d72162ec0bc5ffaccd28 \
        --control-plane --certificate-key 1dd49c0399fbb028895ae47bb9bba21901917827950696b75066fa2852d1870a

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.18.5.20:6443 --token 48f2sx.qsfodgd8wyanmycj \
        --discovery-token-ca-cert-hash sha256:4458c26834f6912027b169bc63fbdbe61bfb9c8b88f5d72162ec0bc5ffaccd28
```

生成Join命令

查看/生成Token

```bash
kubeadm token create
vhm28d.w0dm5ivg10d9iorg
[root@kube-master-1 ~]# kubeadm token list
TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS
vhm28d.w0dm5ivg10d9iorg   23h         2022-05-21T08:24:01Z   authentication,signing   <none>                                                     system:bootstrappers:kubeadm:default-node-token
```

生成`--discovery-token-ca-cert-hash`

```bash
[root@kube-master-1 ~]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed  's/^ .* //'
```

拼接join命令

```bash
kubeadm join 172.18.5.20:6443 --token [TOKEN] --discovery-token-ca-cert-hash sha256:[HASH CODE]
```
